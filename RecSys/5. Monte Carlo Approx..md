확률적 샘플링을 통해 복잡한 수학적 문제를 근사적으로 해결하는 기법

## 기본 원리

어떤 함수 $f(x)$의 기댓값 $E[f(x)]$를 계산하고자 할 때, x의 분포 $p(x)$에서 N개의 샘플을 추출하여 근사할 수 있음:

$$ E[f(x)] \approx \frac{1}{N} \sum_{i=1}^N f(x_i), \quad x_i \sim p(x) $$

이 근사의 정확도는 대수의 법칙(Law of Large Numbers)에 의해 보장되며, 중심극한정리(Central Limit Theorem)에 의해 오차의 분포를 알 수 있음.

## 분산 감소 기법

Monte Carlo 추정의 분산을 줄이기 위한 여러 기법이 있음:

1. 대조 변량(Control Variates): 

   $$ \hat{\mu} = \frac{1}{N} \sum_{i=1}^N f(x_i) - c(\frac{1}{N} \sum_{i=1}^N g(x_i) - E[g(x)]) $$
   
   여기서 $g(x)$는 $E[g(x)]$를 알고 있는 함수임.

2. 층화 샘플링(Stratified Sampling):
   전체 영역을 여러 층으로 나누고, 각 층에서 독립적으로 샘플링함.

3. 상관 샘플링(Correlated Sampling):
   유사한 문제들 간에 동일한 난수 시퀀스를 사용하여 분산을 줄임.

# Basic Sampling Algorithms

## 역변환 샘플링 (Inverse Transform Sampling)

연속 확률 변수 X의 누적 분포 함수(CDF) $F(x)$가 주어졌을 때:

1. U ~ Uniform(0, 1)에서 샘플 u를 추출
2. $x = F^{-1}(u)$를 계산

이렇게 얻은 x는 원하는 분포를 따름.

## 박스-뮬러 변환 (Box-Muller Transform)

표준 정규 분포 N(0, 1)에서 샘플을 생성하는 방법:

1. U1, U2 ~ Uniform(0, 1) 추출
2. $R = \sqrt{-2 \ln{U1}}, θ = 2π U2$
3. $X = R \cosθ, Y = R \sinθ$

X와 Y는 독립적인 표준 정규 분포를 따름.

# Rejection Sampling

목표 분포 p(x)에서 직접 샘플링하기 어려울 때 사용하는 방법임.

## 알고리즘

1. 제안 분포 q(x)와 상수 M을 선택 (M ≥ max(p(x)/q(x)))
2. q(x)에서 샘플 x를 추출
3. Uniform(0, Mq(x))에서 u를 추출
4. u ≤ p(x)이면 x를 받아들이고, 그렇지 않으면 거부
5. 2-4 단계를 원하는 수의 샘플을 얻을 때까지 반복

## 수학적 정당성

제안된 x가 받아들여질 확률:

$$ P(\text{accept}) = \int \frac{p(x)}{Mq(x)} q(x) dx = \frac{1}{M} $$

따라서 받아들여진 샘플의 분포:

$$ p(\text{accepted } x) = \frac{p(x)}{MP(\text{accept})} = p(x) $$

## 효율성

효율성은 1/M으로, M이 클수록 거부율이 높아짐. 따라서 p(x)와 q(x)가 유사할수록 효율적임.

# Importance Sampling

직접 샘플링이 어려운 분포 p(x)에서 기댓값을 계산하기 위한 방법임.

## 기본 원리

$$ E_{p(x)}[f(x)] = \int f(x)p(x)dx = \int f(x)\frac{p(x)}{q(x)}q(x)dx = E_{q(x)}[f(x)\frac{p(x)}{q(x)}] $$

여기서 q(x)는 제안 분포임.

## 알고리즘

1. 제안 분포 q(x)에서 N개의 샘플 {x_i}를 추출
2. 각 샘플에 대해 중요도 가중치 w_i = p(x_i)/q(x_i) 계산
3. 기댓값을 다음과 같이 추정:
   $$ \hat{E}[f(x)] = \frac{\displaystyle\sum_{i=1}^N w_i f(x_i)}{\displaystyle\sum_{i=1}^N w_i} $$

## 분산 감소

Self-normalized Importance Sampling:

$$ \hat{E}[f(x)] = \frac{\displaystyle\sum_{i=1}^N w_i f(x_i)}{\displaystyle\sum_{i=1}^N w_i}, \quad w_i = \frac{p(x_i)}{q(x_i)} $$

이 방법은 정규화 상수를 모르는 경우에도 사용 가능함.

## 효과적인 제안 분포 선택

이상적인 제안 분포: q*(x) ∝ |f(x)|p(x)
실제로는 p(x)와 |f(x)|의 곱과 유사한 분포를 선택하는 것이 좋음.

# 생성 모델에서의 응용

1. VAE (Variational Autoencoder):
   - 잠재 변수 z의 사후 분포 p(z|x)를 근사하기 위해 중요도 가중치 샘플링 사용
   - ELBO의 Monte Carlo 추정:
     $$ \mathcal{L} \approx \frac{1}{N} \sum_{i=1}^N [\log p_\theta(x|z_i) + \log p(z_i) - \log q_\phi(z_i|x)] $$
     여기서 z_i ~ q_φ(z|x)

2. MCMC (Markov Chain Monte Carlo):
   - 복잡한 사후 분포에서 샘플링하기 위해 사용
   - Metropolis-Hastings 알고리즘은 rejection sampling의 일종

3. 파티클 필터 (Particle Filter):
   - 시계열 데이터의 상태 추정에 importance sampling 사용
   - 각 파티클에 중요도 가중치 할당

4. GAN (Generative Adversarial Network):
   - 판별자 학습 시 중요도 샘플링을 통해 효율성 향상 가능

5. 베이지안 신경망:
   - 가중치의 사후 분포에서 샘플링하여 예측 불확실성 추정

# Markov Chain Monte Carlo (MCMC)

MCMC는 복잡한 확률 분포에서 샘플을 생성하는 알고리즘 계열임. 특히 고차원 분포나 정규화 상수를 모르는 분포에서 유용함.

## 기본 원리

1. 목표 분포 π(x)에 수렴하는 마르코프 체인을 구성함
2. 이 체인을 충분히 긴 시간 동안 실행하여 샘플을 얻음

## 이론적 기반

1. 마르코프 체인의 정상 분포 (Stationary Distribution):
   전이 확률 P에 대해, π(x)P(x|y) = π(y)P(y|x) 를 만족하는 π(x)

2. 에르고딕성 (Ergodicity):
   충분히 긴 시간이 지나면 초기 상태와 무관하게 정상 분포에 수렴

3. 상세 균형 조건 (Detailed Balance):
   π(x)P(y|x) = π(y)P(x|y) 를 만족하면 π(x)가 정상 분포임

## Metropolis-Hastings 알고리즘

MCMC의 대표적인 알고리즘 중 하나임.

1. 현재 상태 x에서 제안 분포 q(y|x)를 사용해 후보 상태 y를 생성
2. 수용 확률 α를 계산:
   $$ α = min(1, \frac{π(y)q(x|y)}{π(x)q(y|x)}) $$
3. α의 확률로 y를 수용하고, (1-α)의 확률로 x를 유지

이 과정을 반복하여 π(x)에서의 샘플을 얻음.

## 수렴 진단

1. Gelman-Rubin 통계량: 여러 체인 간의 분산을 비교
2. 자기상관 분석: 샘플 간의 독립성 확인
3. Trace plot: 샘플의 시계열 플롯을 통한 시각적 검사

# Gibbs Sampling

Gibbs Sampling은 MCMC의 특별한 경우로, 다변량 분포에서 샘플링할 때 유용함.

## 기본 원리

각 변수를 다른 모든 변수가 주어졌을 때의 조건부 분포에서 순차적으로 샘플링함.

## 알고리즘

$x = (x_1, ..., x_n)$인 n차원 확률 변수에 대해:

1. 초기값 $x^0 = ({x_1}^0, ..., {x_n}^0)$ 선택
2. 각 반복 t에 대해:
   - ${x_1}^t \sim p(x_1|{x_2}^{t-1}, ..., {x_n}^{t-1})$
   - ${x_2}^t \sim p(x_2|{x_1}^{t},{x_3}^{t-1}, ..., {x_n}^{t-1})$
   - ...
   - ${x_n}^t \sim p(x_n|{x_1}^{t}, ..., {x_{n-1}}^{t})$

## 수학적 정당성

Gibbs Sampling은 다음의 전이 커널을 가진 Metropolis-Hastings 알고리즘의 특수한 경우로 볼 수 있음:

$$ T(x'|x) = p(x'_i|x_{-i}) $$

여기서 x_{-i}는 x_i를 제외한 모든 변수를 의미함. 이 전이 커널은 항상 수용되므로 (α = 1) Metropolis-Hastings 단계가 필요 없음.

## 수렴 특성

1. 에르고딕성: 모든 조건부 분포가 양의 확률을 가지면 에르고딕함
2. 수렴 속도: 변수 간 상관관계가 높을 경우 수렴이 느릴 수 있음
3. 차원의 저주: 고차원에서는 수렴이 느려질 수 있음

## Collapsed Gibbs Sampling

일부 변수를 분석적으로 적분하여 제거한 후 나머지 변수에 대해 Gibbs Sampling을 수행하는 방법. 수렴 속도를 향상시킬 수 있음.

# 생성 모델에서의 응용

1. LDA (Latent Dirichlet Allocation):
   - 토픽 모델링에서 Collapsed Gibbs Sampling 사용
   - 문서-단어 할당을 샘플링:
     $$ p(z_i = k | z_{-i}, w) ∝ (n_{d_i,k,-i} + α_k) · \frac{n_{k,w_i,-i} + β}{n_{k,-i} + Wβ} $$
     여기서 n_{d_i,k,-i}는 현재 단어를 제외한 문서 d_i의 토픽 k 할당 수, n_{k,w_i,-i}는 단어 w_i의 토픽 k 할당 수

2. 베이지안 신경망:
   - 가중치의 사후 분포에서 샘플링:
     $$ p(w_i | w_{-i}, D) ∝ p(D|w)p(w_i|w_{-i}) $$

3. 은닉 마르코프 모델 (HMM):
   - Forward-Backward 알고리즘과 결합하여 상태 시퀀스 샘플링

4. 베이지안 가우시안 혼합 모델:
   - 클러스터 할당과 파라미터를 번갈아가며 샘플링:
     $$ p(z_i = k | z_{-i}, x, μ, Σ) ∝ π_k N(x_i | μ_k, Σ_k) $$
     $$ p(μ_k, Σ_k | z, x) ∝ N(μ_k | m_k, (κ_k Λ_k)^{-1}) W(Λ_k | W_k, ν_k) $$

5. 조건부 임의장 (Conditional Random Fields):
   - 구조화된 예측 문제에서 MCMC를 사용하여 레이블 시퀀스 샘플링

MCMC와 Gibbs Sampling은 복잡한 확률 모델의 사후 분포에서 샘플을 얻는 강력한 도구임. 특히 고차원 문제나 정규화 상수를 계산하기 어려운 경우에 유용함. 생성 모델에서는 모델 파라미터의 불확실성을 추정하고, 잠재 변수의 분포를 탐색하며, 복잡한 사후 분포에서 추론을 수행하는 데 널리 사용됨. 그러나 수렴 속도와 혼합 문제에 주의해야 하며, 효과적인 제안 분포나 샘플링 순서 설계가 중요함.