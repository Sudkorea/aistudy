
Abstract

Gradient Boosting Decision Tree는 유명한 머신러닝 알고리즘이고, XGBoost, pGBRT 등 여러가지 개선 알고리즘들도 나왔으나, 여전히 높은 차원 및 큰 데이터에선 만족스러운 성능이 나오지 않음.

정확도가 어떻게 높은거지?
XGBoost : 데이터가 균형적일떄 사용함
LightGBM : 데이터가 비균형적일때 사용함.
![[21004142-8107-460F-91A1-B64F385E1D55.png]]
시계열 데이터에도 사용할 수 있나?

Boosting : 잔차가 큰쪽을 고려하기 때문?

