# 1. GCN (Graph Convolutional Network)의 탄생 배경과 핵심 개념
GCN은 “스펙트럴(spectral) 그래프 컨볼루션”을 1차 항까지 근사해 계산 복잡도를 O(|E|) 수준으로 낮춘 모델이다. Kipf & Welling은 라플라시안 고유분해 비용을 줄이기 위해 체비셰프 다항식을 도입하고, 이를 다시 단일 파라미터와 르노멀라이즈드 인접행렬로 단순화한 전파 규칙을 제시했다.
이 수식은 (1) 정규화, (2) 이웃 정보 합산, (3) 선형 변환의 세 단계를 통해 노드 임베딩을 “부드럽게(smooth)” 만들고, 라벨이 없는 노드에도 감독 신호를 확산한다.

## 개념 정리
### 라플라스 행렬
그래프의 인접행렬(Adjacency matrix) $A$만으로는 그래프의 연결 상태만을 표현하므로, 더 자세한 특성을 파악하려면 연산량이 생김. 따라서, 행렬에 데이터를 더 넣기 위해 라플라스 행렬 $L$으로  만듦.
$$L = D - A$$
여기서 $D$는 Degree matrix로,
``` mermaid
flowchart LR

A[A] --- B[B]
B --- C[C]
B --- D[D]
C --- D

```
(화살표가 보인다면 무시하기) 이 그래프에서 

|        | A   | B   | C   | D   |
| ------ | --- | --- | --- | --- |
| degree | 1   | 3   | 2   | 2   |
이거다. vertex의 개수임

정규 라플라스 행렬은, 말 그대로 위 식을 정규화시킨거임.

$$ \mathcal{L} = I - D^{\frac{1}{2}}AD^{\frac{1}{2}}$$

이러면 eigenvalue가 0~2로 고정되는 효능, Degree가 너무 커서 생기는 폭주 막아주는 효능 등 많은 효능이 있음.

### Graph Convolution

각 node A, B, C...에 가중치가 들어있음. (예를 들어, 유저 노드에 들어있는 가중치는 개인의 feature)
이 가중치를 활용하여 이웃 노드의 가중치를 업데이트하는 것을 그래프 컨볼루전이라고 함.

이때, 값을 통해 값이 업데이트되는 과정을 거침 -> '변화량' 생김 -> 이래서 라플라시안, 푸리에변환 튀어나오는것.

### Spectral Graph Convolution

CNN이 이미지를 읽는 방식 : 각 픽셀별로 어떻게 생겼나 보면 이미지를 읽을 수 없으니, CNN은 이미지를 조금씩 네모낳게 자르고, 그 네모를 조금씩 옆으로 옮겨가며 그 조각의 패턴을 읽고 이게 뭐일 확률이 크다는 방식으로 이미지를 인식함.

패턴이라는 데서 볼 수 있듯이, 이게 주파수랑 대강 비슷함. 인식한 그림의 확률이 갑자기 바뀌는 지점은 (=주파수가 튀는 지점은) 사진에서 나오는 물체의 경계라고 인지할 수 있음.

그리고, 이렇게 주파수로 나눠서 보는 방식이 푸리에 변환임.

실제로 CNN은 Fourier Transformation을 쓰진 않음, 근데 개념이 비슷하다는거임.

따라서, 그래프 성분을 CNN의 아이디어에 착안해서, Vertex, Edge, Weight의 흐름 주파수가 튀는 지점을 학습시키면 되지 않을까 하는 것이 이 개념임.

단점은, 계산량이 엄청 크다는것. $O(n^3)$임.