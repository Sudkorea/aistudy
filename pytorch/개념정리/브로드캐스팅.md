크기가 다른 텐서들을 연산할 때 자동으로 크기를 맞춰주는 기능. 이를 통해 코드를 더 간결하게 작성할 수 있고, 메모리도 효율적으로 사용할 수 있음.

## 기본 규칙:
1. 각 텐서는 적어도 1차원이어야 함.
2. 뒤에서부터 차원을 비교함.
3. 두 차원의 크기가 같거나, 둘 중 하나가 1이면 호환.
4. 크기가 1인 차원은 다른 텐서의 해당 차원 크기로 확장됨.

## 예시:

```python
# 크기가 (3, 1)인 텐서
a = torch.tensor([[1], [2], [3]])

# 크기가 (1, 4)인 텐서
b = torch.tensor([[1, 2, 3, 4]])

# 브로드캐스팅을 통한 덧셈
c = a + b

print(c.shape)  # torch.Size([3, 4])
print(c)
# tensor([[2, 3, 4, 5],
#         [3, 4, 5, 6],
#         [4, 5, 6, 7]])
```

이 예시에서 a는 (3, 1)로, b는 (1, 4)로 확장되어 연산이 수행되는 것을 확인할 수 있음.

브로드캐스팅의 장점:
1. 코드 간결성: 복잡한 반복문 없이 연산 가능
2. 메모리 효율: 실제로 큰 텐서를 만들지 않고 연산 수행
3. 성능 향상: GPU에서 최적화된 연산 가능

주의사항:
- 의도치 않은 브로드캐스팅으로 예상 외의 결과가 나올 수 있어서, 항상 shape를 확인하는 습관을 들이는 게 좋음
- 너무 큰 차원 간의 브로드캐스팅은 메모리 사용량을 급증시킬 수 있음

expand()와의 관계:
expand()는 이런 브로드캐스팅을 명시적으로 수행하게 해줌. 자동 브로드캐스팅이 애매하거나, 명확히 차원을 확장하고 싶을 때 사용하면 된다.

```python
a = torch.tensor([1, 2, 3])
b = a.expand(3, -1)  # (3, 3) shape으로 확장
```

