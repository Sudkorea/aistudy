llm : 트랜스포머로 바뀌며 비약적인 발전
Transformers : 단점 말하기
계산량 : O(n^2)
이유 : qkv n개의 시퀀스 처리, 하나 처리할때마다 다른 시퀀스를 모두 처리하므로
디코더 : O(n) 처리시간 들음 : 추론 시 
I am cat


처리 시간이 너무 길음
메모리 어떻게 경량화해서 학습시간 줄일 수 없을까?
(이 연구가 모델경량화쪽임)

RNN : O(n) train
finite state 넣으려 하니까, 압축이 안됨
(mamba는 이쪽에 가까움)

abstract
trasnformer 계산비용 다루려고 이것저것 있긴 한데, 어텐션 작동이 잘 안됨

Introduction
Foundation Model :: 최근 Transfomer attention 기술임

이 단점이 window 밖 내용 모델링이 안됨, quadratic scaling 가진게 문제임

---
중요 키워드 : SSM
상태공간방정식(제어이론)
(이산화 과정)
이 구조가 RNN과 굉장히 유사함(SNSM)

RNN과 그럼 뭐가 다르냐?
Time - invariant
A, B가 시간에 따라 변하지 않음
(RNN은 변함)

1. 다 Linearity함.
2. 한번에 계산이 가능함(time-invariant한 특성 덕분)


빌드업
트랜스포머, RNN 장단점 설명

RNN 관점에서 어떤 연구가 이루어졌는가?(Transformers는 이번 수업때 배우는 내용임)

SSM의 단점 (선택적 복사, 유도 헤드) 간단 설명
이래서 오디오나 사진에서는 괜찮았는데 문맥 읽는게 별로였음
근데 왜 이걸 쓰려고 할까?
- RNN의 속도도 좋은데, 한번에 계산하는거때매 더 좋음

이걸 Transformers의 대안으로 사용하면 안될까?


selective space model 설명하며 어떻게 selective copy 진행하는지

LSS, HIPPO, LSSL, S4(D), H3


---
# 불가능의 삼각형

Transformer와 RNN 모델의 "Impossible Triangle" 개념을 설명해드리겠습니다. 이는 세 가지 핵심 특성 간의 상충관계(trade-off)를 나타냅니다:

1. Low-cost Inference (저비용 추론)
- 모델이 실제 서비스에서 추론을 수행할 때 필요한 컴퓨팅 리소스와 시간이 적어야 함
- 실시간 응답이 필요한 서비스에서 특히 중요
- Latency와 throughput 관점에서의 효율성

2. Training Parallelism (학습 병렬화)
- 모델 학습 시 GPU/TPU 등 여러 디바이스에서 효율적으로 병렬 처리가 가능해야 함
- 대규모 데이터셋으로 빠른 학습이 가능해야 함
- 분산 학습 시스템에서의 확장성

3. Strong Performance (높은 성능)
- 주어진 태스크에서 높은 정확도와 성능을 보여야 함
- State-of-the-art에 준하는 결과를 달성해야 함
- 일반화 능력이 뛰어나야 함

이러한 세 가지 특성을 모두 완벽하게 만족시키는 것은 현실적으로 어렵습니다:

- RNN의 경우:
  * Sequential 특성으로 인해 병렬화가 어려움
  * Inference는 상대적으로 가벼움
  * 긴 시퀀스에서 성능 저하 문제

- Transformer의 경우:
  * 뛰어난 병렬화 가능성과 높은 성능
  * Self-attention으로 인한 무거운 추론 비용
  * 메모리 사용량이 시퀀스 길이의 제곱에 비례

이러한 상충관계를 해결하기 위한 다양한 연구가 진행되고 있습니다:
- Sparse/Linear Attention
- Efficient Transformer 구조
- Knowledge Distillation
- 모델 압축 및 최적화 기법

실제 응용에서는 주어진 상황과 요구사항에 따라 세 가지 특성 중 어떤 것을 우선시할지 결정하고, 적절한 타협점을 찾는 것이 중요합니다.
---

# hippo, lssl

LRDs 문제는 RNN과 Transformer 모두에 존재하는 문제이며, 이를 해결하기 위한 접근들입니다. 각각을 자세히 살펴보겠습니다:

1. 문제 상황:
- RNN의 한계: 
  * 기울기 소실/폭발로 인해 긴 시퀀스 처리 어려움
  * LSTM, GRU 등으로 일부 개선했으나 여전히 한계 존재
- Transformer의 한계:
  * Self-attention의 O(n²) 복잡도로 인한 메모리/연산 제약
  * 긴 시퀀스를 처리할 때 리소스 소비가 급격히 증가

2. HiPPO (2020):
- 핵심 아이디어:
  * 시간에 따른 정보의 중요도를 수학적으로 모델링
  * 최근 정보는 높은 해상도로, 과거 정보는 압축해서 저장
- 수학적 기반:
  * Legendre 다항식 등 직교 다항식을 사용
  * 연속적인 시간에서의 정보 투영(projection) 방법 제안
- 의의:
  * 시퀀스 기억을 위한 수학적 프레임워크 제공
  * 하지만 실제 구현은 아직 비효율적

3. LSSL (2021):
- 핵심 아이디어:
  * HiPPO의 개념을 상태 공간 모델로 구현
  * 연속 시간 동역학을 이산화하여 사용
- 구조:
  ```
  x'(t) = Ax(t) + Bu(t)
  y(t) = Cx(t) + Du(t)
  ```
  * A: HiPPO 행렬 사용
  * B, C: 학습 가능한 파라미터
- 한계:
  * 계산 복잡도가 여전히 높음
  * 실용적 사용이 어려움

4. S4 (2021):
- 핵심 혁신:
  * LSSL의 계산을 효율적으로 만듦
  * 특수한 행렬 구조를 활용한 최적화
- 주요 기술:
  * 복소수 대각화를 통한 병렬 처리
  * 특별한 초기화와 파라미터화 방법
- 성과:
  * O(n) 복잡도 달성
  * 긴 시퀀스에서도 효율적 연산 가능
  * 특히 음성, 음악 등 연속적 신호에서 우수한 성능

이러한 발전은 다음과 같은 의의를 가집니다:
1. RNN의 한계를 근본적으로 해결하려는 시도
2. Transformer의 복잡도 문제를 우회하는 새로운 접근
3. 수학적으로 견고한 기반 위에서의 발전
4. 실용적 구현을 위한 점진적 개선

이러한 배경이 있었기에 Mamba가 나올 수 있었고, Mamba는 여기에 선택적 상태 업데이트라는 혁신을 더했습니다. 이 중 특정 부분에 대해 더 자세히 설명이 필요하신가요?

HiPPO의 주요 한계점과 LSSL(Linear State Space Layer)의 개선 방향을 설명드리겠습니다:

HiPPO의 한계점:
1. 학습 안정성 문제
- Polynomial basis를 사용하면서 수치적 불안정성이 발생할 수 있습니다
- 특히 고차 다항식을 사용할 때 이 문제가 두드러집니다

2. 확장성 제한
- 시퀀스 길이가 길어질수록 계산 비용이 크게 증가합니다
- 실제 긴 시퀀스를 다룰 때 효율성이 떨어집니다

LSSL의 개선:
1. 선형 상태 공간 도입
- HiPPO의 다항식 기반 접근을 선형 상태 공간 모델로 일반화했습니다
- 이를 통해 더 안정적인 학습이 가능해졌습니다

2. 디스크리타이제이션 개선
- Bilinear transform을 사용하여 연속 시스템을 이산 시스템으로 더 효과적으로 변환
- 수치적 안정성이 크게 향상되었습니다

3. 병렬화 가능성
- 선형 상태 공간 모델의 특성을 활용해 더 효율적인 병렬 계산이 가능해졌습니다
- 이는 긴 시퀀스 처리에서 특히 중요한 장점이 되었습니다

결과적으로 LSSL은 HiPPO의 기본 아이디어를 유지하면서, 실용적인 측면에서 더 안정적이고 확장 가능한 모델을 제시했다고 볼 수 있습니다.

---
# 상태 공간 방정식
자동차의 현재 위치를 추정하는 문제를 예시로 들어보겠습니다.

자동차의 실제 상태 x (우리가 알고 싶은 것):
- 정확한 위치 (위도, 경도)
- 정확한 속도
- 정확한 방향

하지만 우리가 직접 관측할 수 있는 것(y)은:
1. GPS 신호 (노이즈가 있는 위치 데이터)
2. 속도계 측정값 
3. 나침반 데이터

여기서 문제는:
- GPS는 오차가 있음
- 속도계도 완벽히 정확하지 않음
- 나침반은 주변 금속에 영향을 받을 수 있음

이때 상태 추정을 통해:
1. 이전 위치 정보
2. 물리 법칙(운동 방정식)
3. 현재 관측값들

이 모든 정보를 종합해서 "현재 자동차의 가장 그럴듯한 위치와 상태"를 추정합니다.

예를 들어 칼만 필터는:
- GPS가 갑자기 100m 점프했다고 하더라도
- 이전 위치와 속도를 고려해서
- 물리적으로 가능한 현재 위치를 추정합니다

이것이 바로 "관측값으로부터 실제 상태를 추정하는" 과정의 실제 예시입니다.

# 상태 공간 방정식의 이해

## 1. 상태 공간 방정식이란?
상태 공간 방정식은 시스템의 동적 특성을 내부 상태 변수를 사용하여 표현하는 수학적 모델입니다. 이는 시스템의 입력, 출력, 그리고 내부 상태 간의 관계를 명확하게 기술합니다.

## 2. 기본 형태
### 연속 시간 상태 방정식
```
dx/dt = Ax + Bu  (상태 방정식)
y = Cx + Du      (출력 방정식)
```

### 주요 변수의 의미
- x ∈ ℝᴺ: 시스템의 내부 상태
- u: 입력 신호
- y: 출력 신호
- A: 상태 전이 행렬
- B: 입력 가중치 벡터
- C: 출력 가중치 벡터
- D: 직접 통과항

## 3. 특징과 장점
- 다변수 시스템을 간단하게 표현 가능
- 시스템의 내부 상태를 명시적으로 다룸
- 컴퓨터 시뮬레이션에 적합
- 선형/비선형 시스템 모두에 적용 가능

## 4. 주요 응용 분야
- 제어 시스템 설계
- 신호 처리
- 시스템 식별
- 딥러닝 (LSSL, S4 등의 모델)

## 5. 시스템 분석
상태 공간 방정식을 통해 다음과 같은 시스템 특성을 분석할 수 있습니다:
- 안정성 (A 행렬의 고유값 분석)
- 제어가능성 (Controllability)
- 관측가능성 (Observability)

네, 자동차 예시에서 각 행렬의 의미를 설명해드리겠습니다:

1. A 행렬 (상태 전이 행렬)
- 자동차의 자연스러운 움직임을 표현
- 예: 현재 속도로 인한 위치 변화, 관성으로 인한 속도 변화
```
예시적인 의미:
- 현재 속도가 그대로 유지되면 위치가 얼마나 변할지
- 현재 방향이 유지될 때 위도/경도가 어떻게 변할지
```

2. B 행렬 (입력 가중치)
- 운전자의 조작이 상태에 미치는 영향
- 예: 가속 페달, 브레이크, 핸들 조작의 효과
```
예시적인 의미:
- 가속 페달을 밟았을 때 속도가 얼마나 변하는지
- 핸들을 돌렸을 때 방향이 얼마나 변하는지
```

3. C 행렬 (출력 가중치)
- 실제 상태가 센서에서 어떻게 측정되는지
- 예: GPS, 속도계, 나침반의 측정 방식
```
예시적인 의미:
- GPS가 실제 위치를 어떻게 측정하는지
- 속도계가 실제 속도를 어떻게 읽는지
```

4. D 행렬 (직접 통과항)
- 입력이 즉각적으로 출력에 미치는 영향
- 예: 센서의 즉각적인 반응
```
예시적인 의미:
- 브레이크를 밟았을 때 바로 나타나는 감속도 측정값
- 핸들 조작 시 즉시 변하는 방향 센서 값
```

이렇게 각 행렬은 자동차의 물리적 특성, 제어 입력의 영향, 그리고 센서의 측정 특성을 수학적으로 표현합니다.

---
한계 및 의의

연구 현황:

•시퀀스 모델링: Mamba는 텍스트, 오디오, 유전체학 등 다양한 모달리티에서 Transformer와 유사하거나 더 나은 성능을 보이며, 특히 긴 시퀀스 처리에서 효율적입니다.

•컴퓨터 비전: Mamba는 이미지, 비디오, 포인트 클라우드 등 시각적 데이터 처리에도 적용되어, 연산 복잡도를 줄이면서도 우수한 성능을 보입니다.

•하이브리드 모델: Mamba와 Transformer를 결합한 하이브리드 모델(Jamba)이 개발되어, 52억 개의 파라미터와 256,000 토큰의 컨텍스트 윈도우를 통해 대규모 언어 모델링에서의 가능성을 보여주고 있습니다.

한계점:

•짧은 시퀀스 처리: Mamba는 긴 시퀀스에서 우수한 성능을 보이지만, 짧은 시퀀스나 텍스트와 음성을 함께 처리하는 작업에서는 효율성이 떨어질 수 있습니다.

•특정 작업에서의 성능: Mamba는 복사(copying)나 인-컨텍스트 학습이 중요한 작업에서는 Transformer보다 성능이 낮을 수 있습니다.

의의:

•효율성 향상: Mamba는 시퀀스 길이에 따라 연산 복잡도가 선형적으로 증가하여, 긴 시퀀스 처리에서 Transformer의 한계를 극복합니다.

•다양한 응용 가능성: 텍스트, 오디오, 비전 등 다양한 분야에 적용 가능하며, 특히 긴 시퀀스 데이터 처리에 강점을 보입니다.

•하드웨어 최적화: GPU 메모리 사용을 최소화하는 하드웨어 친화적 알고리즘을 통해, 기존 방법보다 최대 3배 빠른 속도를 구현합니다.