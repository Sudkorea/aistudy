![[Pasted image 20250602105441.png]]

# 이슈발생 상황
CUDA MemoryError
추천 성능이 낮은 문제

# 관련 내용
패턴기반 체크카드 상품 추천 과제 BDBCAR005_M01.py -- 이걸 풍부하게
이걸 하다가 에러 발생했는데, 관련 소스코드는이고, 함

## 전체 흐름
![[Pasted image 20250602163913.png]]

![[Pasted image 20250602155136.png]]


카드 및 패턴 보유 고객 대상 추천 로직인 card_rec_1에서 아래 문제 발생.

## CUDA MemoryError

### 문제가 된 소스코드 부분
![[Pasted image 20250602170552.png]]
``` python
N = int(len(i_CSNO_LIST)/10)

similar_model = implicit.als.AlternatingLeastSquares()

similar_model.fit(df_i_csr, show_progress=False)

select_csno=np.arange(len(i_CSNO_LIST))      

rec = similar_model.similar_users(select_csno,N=N)[0] # <<<< 이 부분에서 에러 발생
```
각 배치별 als 모델을 불러온 뒤, 유저별로 similar_users를 생성하는 과정에서 문제 발생

### Error Message
```
File “_cuda.pyx”, line 78, in implicit.gpu_cuda.KnnQuery.topk

MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/project/_skbuild/linux-x86_64-3.8/cmake-build/_deps/rmm-src/include/rmm/mr/device/pool_memory_resource.hpp:183: Maximum pool size exceeded
```
CUDA에서 out of memory인 것을 보아, 기존 GPU 메모리 사이즈인 7~8GB를 넘기는 문제 발생

## 추천 성능이 낮은 문제
가 있음.
정합성 문제가 생기는 부분이 존재했다. 이거때문에 뭐가 잘못됐다

# 원인 분석
## CUDA MemoryError
### N 크기 문제 (+ 대분류 데이터 파라미터 이슈) (이걸 줄글로 좀 더 쓰기)
#### 작동 시 문제점
![[Pasted image 20250602170737.png]]
- `N = int(len(i_CSNO_LIST)/10)`으로 설정되어 있음. 2025년 5월 기준 `int(len(i_CSNO_LIST))`의 최댓값은 약 97000이므로, N의 최댓값은 약 9700임.
- `rec = similar_model.similar_users(select_csno,N=N)[0]`를 해석하면 각 유저별 N명의 similar users를 뽑아오도록 함.
- 계산해보면, 97000명의 유저에게 각 9700명의 추천 유저 및 스코어를 담은 3차원 행렬이 나옴.
- `97000 * 9700 * 4(bytes) * 2 = 7.5GB`이므로, GPU 용량 한계에 아슬아슬하게 걸쳐져 있음.
- 결론 : 시간이 지나며 유저가 늘어남에 따라 GPU 용량 바운더리를 넘었다고 해석 가능함.

#### N 크기에 대한 본질적인 문제점
- 유사도를 살펴보면 다음과 같음.
	- 상위 10, 20, 50, 100명, 10%의 코사인 유사도 평균값, 중위값 비교
	  (남성 50대에서 실험 진행. 총 50395명)

|     | N=10 | N=20 | N=50 | N=100 | N=전체 인원의 10% |
| --- | ---- | ---- | ---- | ----- | ------------ |
| 평균값 | 0.95 | 0.94 | 0.93 | 0.91  | 0.75         |
| 중위값 | 0.95 | 0.94 | 0.92 | 0.91  | 0.74         |
| 최솟값 | 0.94 | 0.93 | 0.91 | 0.89  | 0.69         |
평균값, 중위값이 0.75인 것을 보아, 전체 인원의 상위 10%를 사용할 경우 비교적 유사도가 낮은 사람들의 데이터가 많이 섞임.

- 업계/학계 유사 이웃 수(`N`) 설정 사례

| 출처                             | 적용 대상                    | 유사 이웃 수(`N`)     | 주요 내용                       |
| ------------------------------ | ------------------------ | ---------------- | --------------------------- |
| Netflix Prize (BellKor team)   | User-based CF            | N = 20~50        | 가장 영향력 있는 상위 이웃만 고려하여 성능 향상 |
| Amazon (Linden et al., 2003)   | Item-based CF            | N = 20~50        | 실시간성과 정확도 균형을 위한 적정 유사 이웃 수 |
| `Surprise` 라이브러리 (Scikit)      | KNNBaseline, KNNBasic 등  | 기본값: N = 40      | 학습·예측 효율성과 품질을 고려한 default  |
| Spotify (Rendle et al., 2020)  | ALS-based implicit model | N = 30           | 코사인 유사도 기반 추천에 최적 N 값 실험    |
| Google RecSys 튜토리얼 (2022)      | User-user CF             | N = 10~50        | 유사도 상위 소수만 사용, 성능 저하 없음     |
| ALS 실무 튜닝 가이드 (implicit 공식 문서) | Similar users/items      | 일반적으로 N = 10~100 | 과도한 N은 성능 대비 효율성 저하 발생      |

## 추천 성능이 낮은 문제

### 문제가 된 소스코드 부분
``` python
이용집계 = card_dummies_df2.loc[rec[0],].sum(axis=0)[1:].sort_values(ascending=False)
```
위 문제를 해결하기 위해 소스 코드를 살펴보다 발견한 내용. 
`rec[0]`은 각 유저별 생성한 similar_users의 0번째 index 유저 데이터

# 조치 사항
## CUDA MemoryError

`N = min(int(len(i_CSNO_LIST)/10), 20)`
근거1, 2에 따라 유사 업계 사례에 맞추어 N의 값을 20으로 낮춤.(추후 N값 실험하며 조정 여지 있음)
N이 9700에서 20으로 낮아짐에 따라, GPU 사용량이 최대 $\frac{1}{300}$만큼 줄어드는 효과 발생.

## 추천 성능이 낮은 문제
``` python
이용집계 = card_dummies_df2.loc[rec[k],].sum(axis=0)[1:].sort_values(ascending=False)
```
0을 k로 변경하여 for문에서 각 유저별로 본인의 유사 유저 데이터를 사용하도록 조정함.


![[Pasted image 20250602144918.png]]


# 이후 오류 발생 가능성 있는 사항

- 잠재적 문제 사항
  20명이 가지고 있는 카드들을 전부 가진 사람이 존재할 경우, 추천 리스트가 만들어지지 않을 수 있음. 
- 해결책
  만약 에러가 발생하는 경우, 에러가 해결될때까지 `N += 10`이 가장 간단할 것으로 사료됨.