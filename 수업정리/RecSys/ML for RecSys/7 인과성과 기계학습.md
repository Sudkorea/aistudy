![[[MLforRecSys] (9강) 인과성과 기계학습 I.pdf]]

# 인과성 개요

## 인과성(Causality)

개념이 뭔진 잘 알아서 멀 쓸지 감이 안잡힘

### **Average Treatment Effect (ATE)와 Conditional Average Treatment Effect (CATE) 개념 설명**

✅ **1. Average Treatment Effect (ATE)**

- ATE는 **처치(treatment)의 평균적인 효과**를 측정하는 값이다.
- 보통 처치 집단과 통제 집단 간의 **평균적인 결과 차이**를 나타냄.
- 실험이나 관찰 연구에서 특정 개입(예: 약물, 마케팅 캠페인)이 전체 모집단에 미치는 평균적인 영향을 측정하는 데 사용됨.

🔹 **수식 표현**

$$ATE = E[Y(1)] - E[Y(0)]$$

- $E[Y(1)]$: 처치를 받은 경우의 기대 결과
- $E[Y(0)]$: 처치를 받지 않은 경우의 기대 결과

✅ **2. Conditional Average Treatment Effect (CATE)**

- CATE는 ATE와 비슷하지만, 특정 조건(특정 그룹 또는 개별 특성)에 따라 달라지는 **개별적인 처치 효과**를 측정함.
- 예를 들어, 특정 연령대, 성별, 소득 수준을 고려했을 때 **처치의 효과가 어떻게 달라지는지** 분석하는 것.

🔹 **수식 표현**

$$CATE(x) = E[Y(1) | X = x] - E[Y(0) | X = x]$$

- $X  = x$ : 특정 조건(예: 특정 연령대, 성별, 지역 등)에 해당하는 경우의 기대 효과

✅ **차이점**



|  |**ATE**|**CATE**|
|---|---|---|
|정의|전체 모집단의 평균적인 처치 효과|특정 그룹 또는 개별 특성에 따른 처치 효과|
|적용 범위|모집단 전체|부분집단 또는 개별 수준|
|활용 예시|신약의 평균 효과 분석|특정 연령대별 신약 효과 분석|

---

### **중요한 질문 선정 (5가지 접근법 중 선별)**

📌 **1. "내가 교수라면" 접근법**

- ATE와 CATE의 차이를 **하나의 직관적인 비유**로 설명한다면 어떻게 할 수 있을까?

📌 **2. "실전 적용" 접근법**

- 온라인 광고 캠페인에서 ATE와 CATE를 활용하여 효과적인 타겟팅 전략을 수립하려면 어떻게 해야 할까?

📌 **3. "반대의 관점" 접근법**

- ATE만 사용하고 CATE를 고려하지 않는다면 어떤 문제점이 발생할까?
- 
## **Neural Network and Meta-Learner**

### **1. Neural Network 개념**

Neural Network(신경망)은 다층 퍼셉트론(Multi-layer Perceptron, MLP)과 같은 구조를 갖는 모델로, 데이터에서 패턴을 학습하는 비선형 함수 근사기이다. 주요 구성 요소는 다음과 같다.

- **입력층(Input Layer)**: 데이터의 특징(feature)이 입력되는 층.
- **은닉층(Hidden Layers)**: 입력층과 출력층 사이의 층으로, 활성화 함수(Activation Function)를 사용해 비선형 변환을 수행.
- **출력층(Output Layer)**: 최종 예측값을 출력하는 층.

Neural Network는 가중치(Weight)와 편향(Bias)을 조정하여 학습하며, Backpropagation 알고리즘과 Gradient Descent 최적화를 활용해 성능을 향상시킨다.

---

### **2. Meta-Learner 개념**

Meta-Learning(메타 러닝)은 학습 알고리즘이 자체적으로 더 나은 학습을 수행할 수 있도록 돕는 기법이다. 일반적으로 **Few-shot Learning**이나 **Domain Adaptation** 같은 문제를 해결하기 위해 사용된다. Meta-Learner는 다음과 같은 주요 기능을 수행한다.

- **Task 간 일반화 능력 학습**: 모델이 새로운 태스크에도 빠르게 적응하도록 학습.
- **Hyperparameter Optimization**: 학습 과정에서 최적의 하이퍼파라미터를 자동으로 조정.
- **Adaptation Strategy**: 새로운 데이터 분포에 맞게 모델이 빠르게 적응하는 방법 학습.

---

## **3. Meta-Learner의 종류: T-Net, S-Net, S-Learner, T-Learner**

Meta-Learner는 주로 **처치 효과(치료 효과, Treatment Effect)를 추정**하는 분야에서 사용되며, 특히 Causal Inference(인과 추론)에서 중요한 역할을 한다. 대표적인 방법으로 **S-Learner, T-Learner, T-Net, S-Net**이 있다.

### **(1) T-Net, S-Net**

이 모델들은 Neural Network 기반으로 Treatment Effect를 추정하기 위한 신경망 구조이다.

#### **T-Net (Treatment Net)**

- 처치 변수(Treatment Variable)를 입력에 추가한 후, 뉴럴 네트워크가 전체적인 관계를 학습하는 구조.
- 하나의 네트워크에서 처치 유무에 따른 출력값을 함께 학습.
- **장점**: 단일 모델로 처리 가능하며, 데이터 샘플이 적을 때 강점.
- **단점**: 처치 효과가 매우 비선형일 경우 모델이 과적합될 가능성이 있음.

#### **S-Net (Selection Net)**

- 선택 편향(Selection Bias)을 보정하기 위해 학습된 Neural Network.
- 처치 여부를 예측하는 네트워크와 실제 효과를 추정하는 네트워크로 구성됨.
- 다양한 편향을 조정하는 데 강점이 있음.

---

### **(2) S-Learner & T-Learner**

T-Net과 S-Net이 Neural Network 기반이라면, S-Learner와 T-Learner는 보다 일반적인 머신러닝 기반 방법론이다.

#### **S-Learner (Single Learner)**

- **하나의 모델**을 사용하여 처치(Treatment)를 고려한 예측을 수행.
- 수식: $$\hat{Y} = f(X, T)$$ 여기서, X는 Feature, T는 Treatment Variable, ff는 학습된 모델.
- 같은 모델에서 처치가 적용되지 않았을 때( $T=0$ )와 적용되었을 때( $T=1$ )의 차이를 비교하여 처치 효과를 추정.
- **장점**: 단순한 모델링, 모든 데이터 사용 가능.
- **단점**: 처치 효과를 정확하게 추정하기 어려울 수 있음.

#### **T-Learner (Two Learners)**

- **두 개의 별도 모델**을 학습하여 처치 그룹과 비처치 그룹의 관계를 따로 모델링.
- 두 개의 예측 모델을 학습한 후, 두 모델 간의 예측 차이를 처치 효과로 추정.
- 수식:$$ \hat{Y}_0 = f_0(X), \quad \hat{Y}_1 = f_1(X)$$ 처치 효과 추정: $$\hat{\tau}(X) = \hat{Y}_1 - \hat{Y}_0$$
- **장점**: 개별적인 학습으로 더 강력한 추론 가능.
- **단점**: 데이터가 적으면 두 개의 모델을 학습하는 것이 어려울 수 있음.

---

## **4. 비교 정리**

|Model|특징|장점|단점|
|---|---|---|---|
|**T-Net**|Treatment을 직접 예측하는 Neural Network|단일 모델로 학습 가능|비선형 관계에서 과적합 가능|
|**S-Net**|Selection Bias 보정하는 Neural Network|Selection Bias 조정 가능|복잡한 모델 구조|
|**S-Learner**|하나의 모델로 처치 효과 추정|단순한 모델링|처치 효과 학습이 어려울 수 있음|
|**T-Learner**|두 개의 개별 모델로 처치 효과 추정|강력한 추론 가능|데이터 부족 시 학습 어려움|

---

## **5. 중요한 질문**

📌 **"If I were a professor" approach**

- S-Learner와 T-Learner를 각각 Neural Network로 확장하려면 어떤 방식이 효과적일까?

📌 **"Real-world application" approach**

- 실제 의료 연구에서 T-Learner와 S-Learner를 어떻게 적용할 수 있을까?

📌 **"Opposing perspective" approach**

- T-Learner보다 S-Learner를 선호해야 하는 상황은 어떤 경우일까?

📌 **"Graph/mathematical representation" approach**

- T-Learner의 수식을 일반적인 Neural Network 손실 함수와 비교하면 어떤 차이가 있을까?

![[[MLforRecSys] (10강) 인과성과 기계학습 II.pdf]]
### **1. Why Randomized Controlled Trials (RCTs) Are Not Always Feasible**

Randomized Controlled Trials (RCTs)는 인과 관계를 검증하는 가장 강력한 방법 중 하나지만, 현실적으로 항상 실행할 수 있는 것은 아니다. 그 이유는 다음과 같다.

1. **윤리적 문제 (Ethical Concerns)**
    
    - 의료 실험에서 치료군과 대조군을 무작위로 할당하는 것은 생명을 위협할 수 있다. 예를 들어, 흡연이 폐암을 유발하는지를 알아보기 위해 무작위로 사람들에게 흡연을 강요할 수는 없다.
2. **비용 문제 (Cost Constraints)**
    
    - RCT는 실험 설계, 피험자 모집, 데이터 수집 등 막대한 비용이 든다. 특히 사회과학 및 경제학에서는 현실적으로 RCT를 수행하기 어렵다.
3. **시간 문제 (Time Constraints)**
    
    - RCT는 장기간의 데이터를 요구하는 경우가 많다. 특정 정책이나 의학적 개입의 효과를 관찰하는 데 수년이 걸릴 수도 있다.
4. **외부 타당성 문제 (External Validity)**
    
    - 실험이 특정 그룹에서 이루어졌다면, 그 결과가 일반적으로 적용될지 확신할 수 없다. 예를 들어, 한 나라에서 수행한 교육 실험이 다른 나라에서도 동일한 효과를 가질지 보장할 수 없다.

---

### **2. Why Theories May Be Wrong**

과학적 이론은 경험적 데이터를 기반으로 하지만, 몇 가지 이유로 인해 오류가 있을 수 있다.

1. **데이터의 한계 (Limitations of Data)**
    
    - 이론은 종종 기존 데이터에서 패턴을 발견하여 세워지지만, 관찰되지 않은 요인이나 편향된 데이터가 존재할 수 있다.
2. **잘못된 가정 (Faulty Assumptions)**
    
    - 이론은 특정 가정을 기반으로 한다. 그러나 가정이 틀렸다면 이론 자체도 무너질 수 있다.
3. **관찰되지 않은 변수 (Unobserved Confounders)**
    
    - 인과 관계를 제대로 분석하려면 모든 중요한 변수를 고려해야 하지만, 실제로 모든 요인을 측정하는 것은 어렵다.
4. **이론의 변화 가능성 (Evolving Nature of Theories)**
    
    - 과학은 계속 발전하기 때문에 기존 이론이 새로운 증거에 의해 수정되거나 반박될 수 있다.

---

### **3. Why Experts May Disagree**

전문가들도 같은 주제에 대해 서로 다른 의견을 가질 수 있다. 그 이유는 다음과 같다.

1. **다른 방법론 (Different Methodologies)**
    
    - 같은 문제라도 사용하는 데이터 분석 기법이나 모델이 다르면 서로 다른 결론을 내릴 수 있다.
2. **해석의 차이 (Differences in Interpretation)**
    
    - 동일한 데이터를 보더라도 전문가마다 해석이 다를 수 있다.
3. **분야 간 시각 차이 (Interdisciplinary Discrepancies)**
    
    - 예를 들어, 경제학자와 의학자가 공공 의료 정책에 대해 서로 다른 접근법을 가질 수 있다.
4. **이해관계 (Conflicts of Interest)**
    
    - 특정 연구가 산업 또는 정부 정책과 연관되어 있다면, 연구자가 의도적으로 편향된 결론을 내릴 가능성도 있다.

---

### **4. Why John Snow Might Be in Your Lecture Notes**

John Snow(1813–1858)는 **근대 역학(Epidemiology)의 창시자**로, **콜레라 확산의 인과 관계를 분석한 대표적인 사례** 때문이다. 그는 1854년 런던의 콜레라 유행 동안 다음과 같은 방식으로 역학 조사를 수행했다.

1. **Broad Street Pump Investigation**
    
    - 런던 소호(Soho) 지역에서 콜레라가 확산되었을 때, John Snow는 환자들이 특정 수도 펌프(Broad Street Pump) 근처에 집중되어 있다는 점을 발견했다.
    
2. **인과 추론 (Causal Inference)**
    
    - 당시 대부분의 전문가들은 콜레라가 공기 전염(Miasma Theory) 때문이라고 믿었지만, Snow는 **수돗물 오염이 원인**이라는 가설을 세웠다.
    - 콜레라 환자들의 주소를 지도에 표시한 후, 감염이 특정 수도 펌프 주변에서 집중된다는 사실을 확인했다.
    
3. **개입(Intervention)과 검증**
    
    - Snow는 Broad Street Pump의 핸들을 제거하여 더 이상 사용하지 못하도록 만들었고, 이후 콜레라 발생률이 급감하는 것을 관찰했다.

이 사례는 **인과 추론(Causal Inference)**과 **Causal Discovery**에서 실험이 불가능한 경우에도 관찰 데이터를 통해 원인을 밝힐 수 있음을 보여주는 중요한 예시이다.

---

### **5. What is Causal Discovery?**

Causal Discovery(인과 발견)는 **데이터에서 인과 관계를 자동으로 학습하는 방법**을 의미하며, 주요 기술은 다음과 같다.

4. **Graphical Models (인과 그래프 모델)**
    
    - 데이터를 기반으로 **방향성이 있는 그래프(Directed Acyclic Graph, DAG)** 를 생성하여 변수 간 인과 관계를 표현.
    - John Snow의 연구처럼 **콜레라 발생 → 오염된 수도 펌프 사용**과 같은 인과 구조를 분석하는 데 사용됨.
5. **Intervention-Based Approaches**
    
    - RCT처럼 직접 개입을 수행하여 인과 관계를 확인하는 방법.
    - 그러나 개입이 불가능한 경우에는 **통계적 방법**으로 인과 구조를 탐색해야 함.
6. **Statistical Causal Discovery Methods**
    
    - **PC Algorithm**: 독립성 검정을 기반으로 DAG를 학습하는 방법.
    - **LiNGAM**: 비정상적인(non-Gaussian) 데이터를 사용하여 선형적인 인과 관계를 학습.
    - **Granger Causality**: 시간 데이터를 활용하여 원인과 결과의 방향성을 분석.

---

### **6. Important Questions**

📌 **"If I were a professor" approach**

- John Snow의 콜레라 연구에서 DAG(Directed Acyclic Graph) 개념을 활용하여 설명한다면 어떤 구조가 될까?

📌 **"Real-world application" approach**

- 의료 데이터에서 Causal Discovery를 활용하여 특정 약물이 실제로 효과가 있는지 확인하는 방법은?

📌 **"Opposing perspective" approach**

- 인과 그래프 없이 단순한 상관 관계 분석만으로도 충분할까?

📌 **"Graph/mathematical representation" approach**

- Causal Discovery에서 Structural Equation Model(SEM)과 DAG의 수학적 차이점은 무엇인가?

📌 **"Practice problem" approach**

- 특정 질병과 환경적 요인 간의 인과 관계를 DAG로 모델링하는 문제를 해결해 보자.



---
## **1. Makarov Equivalence**

Makarov Equivalence는 **정보 이론(Information Theory)**에서 등장하는 개념으로, 확률 변수 간의 정보 제약을 정의하는 방법 중 하나이다. 이는 특히 **제약 조건을 고려한 확률적 독립성(Probabilistic Independence under Constraints)**을 다루며, 인과 추론(Causal Inference)에서도 관련이 있다.

### **(1) 핵심 개념**

Makarov Equivalence는 특정한 조건하에서 확률 분포 간의 **제약 조건(Constraints)**을 만족하는 경우, 두 확률 분포가 동일한 정보적 성질을 가진다고 정의한다.

- **정보 제약(Information Constraints)**: I(X;Y)≤CI(X; Y) \leq C 여기서 I(X;Y)I(X; Y)는 상호정보량(Mutual Information)이며, CC는 주어진 제약 값이다.
- 만약 두 개의 확률 분포 P(X,Y)P(X, Y)와 Q(X,Y)Q(X, Y)가 동일한 제약을 만족한다면, 이들을 **Makarov Equivalence Class**에 속한다고 본다.

### **(2) 인과 추론과의 연결**

- 인과 관계를 분석할 때, 확률 분포가 제약된 상태에서도 동일한 독립 조건(Conditional Independence)을 만족하는 경우, Makarov Equivalence를 활용하여 변수 간 관계를 분석할 수 있다.
- 예를 들어, Causal Discovery에서 **도메인 지식 없이도 특정한 정보 이론적 제약을 통해 인과 구조를 탐색**할 수 있다.

---

## **2. Causal Discovery Assumptions (인과 발견의 기본 가정들)**

Causal Discovery(인과 발견)는 관찰된 데이터에서 변수 간의 인과 관계를 학습하는 기법이다. 이를 수행하기 위해서는 몇 가지 가정을 기반으로 한다.

### **(1) 주요 가정**

1. **Causal Markov Condition**
    
    - 어떤 변수 XX가 원인(Parent Nodes)을 가지면, **XX는 원인들로부터만 영향을 받으며, 다른 비원인 변수들과는 독립적**이다.
    - 수식적으로 표현하면: P(X∣Parents(X))=P(X∣All Ancestors(X))P(X | \text{Parents}(X)) = P(X | \text{All Ancestors}(X))
2. **Faithfulness Assumption (성실성 가정)**
    
    - 독립 조건이 확률적 우연으로 인해 발생하는 것이 아니라 **실제 인과 구조에 의해 결정**된다고 가정한다.
    - 즉, 특정한 독립성이 존재한다면 이는 기본적인 인과 그래프의 구조에 의해 설명될 수 있어야 한다.
3. **Causal Sufficiency (인과적 충족성)**
    
    - **모든 중요한 변수(Confounders 포함)**가 모델에 포함되어 있어야 한다.
    - 만약 **Unobserved Confounder**가 존재하면, 발견된 인과 관계가 실제와 다를 가능성이 높다.
4. **Aciclicity Assumption (비순환성 가정)**
    
    - 인과 그래프(Directed Acyclic Graph, DAG)는 **순환 구조를 가지지 않는다**.
    - 즉, X→Y→ZX \rightarrow Y \rightarrow Z 라는 관계가 존재할 때, 다시 Z→XZ \rightarrow X로 돌아오는 경우는 허용되지 않는다.
5. **Intervention (개입 가능성)**
    
    - 인과 관계를 정확하게 식별하려면 특정 변수에 대해 개입(Intervention)할 수 있어야 한다.
    - RCT(Randomized Controlled Trial)처럼 **변수를 인위적으로 변경하여 결과를 확인하는 과정**이 필요하다.

---

## **3. PC Algorithm (Peter-Clark Algorithm)**

PC 알고리즘은 **조건부 독립 검정(Conditional Independence Test)**을 기반으로 **DAG(Directed Acyclic Graph)**를 학습하는 대표적인 방법이다.

### **(1) 핵심 아이디어**

- **독립성 검정을 사용하여 인과 그래프를 추론**하는 기법이다.
- 방향성이 없는 **Skeleton Graph**를 먼저 학습한 후, **방향성을 부여**하여 DAG를 생성한다.
- Causal Discovery에 활용되며, 특히 **Gaussian 분포 기반 데이터**에서 강력한 성능을 보인다.

### **(2) 알고리즘 과정**

6. **Step 1: Initial Graph Construction**
    
    - 모든 변수 간 **완전 그래프(Complete Graph)**를 생성한다.
7. **Step 2: Edge Removal via Conditional Independence Tests**
    
    - **조건부 독립 검정(Conditional Independence Test)**을 수행하여 독립성을 가지는 변수 간의 엣지를 제거한다.
    - 독립 검정 예시: X⊥Y∣ZX \perp Y \mid Z → 만약 XX와 YY가 ZZ를 고려했을 때 독립이라면, X−YX - Y 엣지를 삭제.
8. **Step 3: Orienting Edges**
    
    - 방향성을 부여하여 DAG를 생성.
    - 삼각형 구조 **(X → Y, X → Z, but Y - Z)**에서 방향성을 정하는 **Collider Detection**을 수행.
9. **Step 4: Consistency Check**
    
    - 최종적으로 DAG의 비순환성(Acyclic Property)을 확인하고 조정.

### **(3) 장점과 단점**

|장점|단점|
|---|---|
|데이터 기반으로 인과 관계를 추론 가능|조건부 독립 검정이 많아질수록 계산량이 증가|
|비지도 학습 기반으로 활용 가능|측정되지 않은 변수(Confounder) 존재 시 성능 저하|
|Gaussian 분포 데이터에서 높은 성능|변수 개수가 많을수록 계산이 느려질 수 있음|

---

## **4. Continuous Optimization (연속 최적화)**

연속 최적화(Continuous Optimization)는 **목적 함수(Objective Function)**를 최적화하는 과정으로, 기계 학습 및 Causal Discovery에서도 중요한 역할을 한다.

### **(1) 기본 개념**

- 목적 함수 f(x)f(x)를 최소화 또는 최대화하는 해 x∗x^*를 찾는 과정.
- 수식적으로: x∗=arg⁡min⁡xf(x)x^* = \arg\min_{x} f(x)
- Neural Network 학습 과정에서 **Gradient Descent**와 같은 방법을 사용하여 가중치를 최적화.

### **(2) Causal Discovery에서 Continuous Optimization 활용**

10. **DAG 구조 학습**
    
    - DAG를 학습하는 과정에서 **연속적인 손실 함수(Continuous Loss Function)**를 설정하여 최적화 가능.
    - Graph Learning 기반 방법에서 DAG의 방향성을 최적화하는 데 활용.
11. **DAG Constraint를 연속적으로 표현**
    
    - DAG는 비순환성을 가져야 하므로, 이를 **연속적인 최적화 문제**로 변환하여 풀 수 있음.
    - 예시: DAG의 방향성을 최적화하는 Lagrangian Relaxation 기법.
12. **Causal Effect Estimation**
    
    - 처치(Treatment)와 결과(Outcome) 간의 인과 관계를 연속 최적화를 통해 추정.

### **(3) 주요 기법**

|최적화 기법|설명|
|---|---|
|Gradient Descent|가장 기본적인 미분 기반 최적화 알고리즘|
|Stochastic Gradient Descent (SGD)|랜덤 샘플링을 통해 빠르게 최적화|
|ADAM|학습률을 자동 조절하여 수렴 속도 향상|
|L-BFGS|고차원 데이터에서 효과적인 최적화 기법|

---

## **5. Important Questions**

📌 **"If I were a professor" approach**

- PC 알고리즘을 Continuous Optimization 기법을 활용하여 개선할 수 있는 방법은?

📌 **"Real-world application" approach**

- Makarov Equivalence 개념을 활용하여 데이터에서 인과 관계를 어떻게 유추할 수 있을까?

📌 **"Opposing perspective" approach**

- Faithfulness Assumption이 항상 유효하지 않다면, Causal Discovery에서 어떤 문제가 발생할까?

📌 **"Graph/mathematical representation" approach**

- DAG 구조에서 Continuous Optimization을 활용하여 방향성을 학습하는 방법을 수식적으로 나타낼 수 있을까?
