![[[모델최적화및경량화] (2강) Pruning.pdf]]


# Pruning이란?
신경망 모델에서, 노드나 연결 제거해서 모델의 크기, 계산 비용 줄이는것

검증 방법 은근 쉬움. 그냥 이상치 때려넣고 변화 작으면 없애는듯?
드롭아웃 정규화 - 90%까지 잘라내도 괜찮을 수 있음.


## 복권 가설


## Unstructured vs Structured (몇개만 빼냐, 모델 구조를 바꿔서 레이어를 빼냐)

## Taxnomy of Pruning

### Scoring
중요도 계산법 : 파라미터/레이어 크기
파라미터 크기 = 절대값 쓰면 되겠죠?
레이어 크기 = L^p norm 비교하는거임.. 이거 위상수학이네요


Global Pruning
Local Pruning
레이어에서 몇퍼센트씩 깔거냐

잘 생각해보면 진짜 별거아니네ㅋㅋ 그냥 수학적으로 모든 경우의수 다해보는거네


## Scheduling
One-shot
pruning 한번만 진행

Recursive
pruning을 여러번에 걸쳐서 진행함

### Initialization
pruning 진행 후 

Weight-preserving (classical method)

Weight-reinitialization
pruning 한 다음 랜덤으로 초기화시킴(성능은 안정ㅇ적인데 재학습 필요해서 오래걸림)

Iterative Magnitude Pruning

# Pruning 심?화

![[[모델최적화및경량화] (3강) Pruning (2).pdf]]

## Advanced Concepts

### Matrix Sparsity
희소성. 0이 얼마나 있는가
- sparse
- dense

Unstructured pruning은 파라미터 값을 0으로 바꾸는 방식
이 방식은 곧바로 계산 속도가 빨라지지 않음.
- 여전히 0을 저장하고 있고
- 여전히 0을 곱함

해결책 : 딥러닝의 계산량 대부분은 행렬 연산이 차지
- 1. Sparsity가 심한 경우 : Sparse Matrix Representation
- 2. Sparsity가 적당한 경우 : 전용 하드웨어 사용

#### Sparse Matrix Representation
쉽게 말하면, 행렬을 통으로 저장하는게 아니라, 0이 아닌 값의 좌표를 저장하는거임
- sparsity가 1/3 미만일 때 효율적임


### Sensitivity Analysis
