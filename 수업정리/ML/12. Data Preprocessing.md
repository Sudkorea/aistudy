# Zero Centering - Normalization

- 모든 입력값이 양수인 상황을 가정함. 이는 sigmoid 함수와 비슷한 상황을 만들 수 있음.
- 데이터에서 평균을 빼는 것은 zero-centering에 도움을 줌.
- normalize하기 위해 표준편차로 나눔.

### 수식

$$X_{normalized} = \frac{X - \mu}{\sigma}$$

$\mu$는 평균, $\sigma$는 표준편차

# Warum Nullzentrierung?

- weight의 작은 변화에 덜 민감해짐.
- 최적화가 더 쉬워짐.

# PCA & Whitening

## PCA (Principal Component Analysis)
데이터를 정규화하여 zero-center로 만들고 주요 축을 정렬함.

## Whitening
공분산 행렬을 단위 행렬로 변환함. 각 축은 동일한 중요도를 가짐.

### 수식
$$X_{whitened} = \Lambda^{-\frac{1}{2}} U^T X$$

여기서 $\Lambda$는 고유값 대각행렬, $U$는 고유벡터 행렬임.

# Data Augmentation

- 실제 데이터셋의 양은 제한적임. 데이터의 의미에 영향을 주지 않고 각 데이터를 수정하는 방법들이 존재함.
- 분류기(classifier)는 이러한 변형에 불변해야 함.
- 큰 데이터셋을 구축하는 것은 비용이 많이 들기 때문에, 기존 데이터를 최대한 활용함.

데이터 증강 기법 예시:
1. 이미지 회전
2. 크기 조정
3. 색상 변경
4. 노이즈 추가
